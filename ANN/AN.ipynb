{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPseZih3m5JI3bzBZ9bAqFj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khoaht312/computational-intelligence/blob/main/ANN/AN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Artificial Neuron**\n"
      ],
      "metadata": {
        "id": "l7Odd7YJJcjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. Definition**\n",
        "- An $AN$, implements a nonlinear mapping from $ℝ^I$ usually to $[ 0,1 ] \\text{ or } [-1,1]$, depending on the activation function used. That is,\n",
        "\n",
        "$f_{AN}:ℝ^I \\to [0,1] \\text{ or }f_{AN}:ℝ^I \\to [-1,1]$ ($I$ is the number of input signals to the $AN$).\n",
        "- An $AN$ receives a vector of $I$ input signals,\n",
        "\n",
        "$\t\\mathbf{z} = (z_1,z_2,...,z_I)$\n",
        "\n",
        "- To each input signal, $z_i$ is associated a weight, $v_i$, to strengthen or deplete the input signal.\n",
        "\n",
        "- The $AN$ computes the net input signal, and uses an activation function $f_{AN}$ to compute the output signal, $o$, given the net input. The strength of the output signal is further influenced by a threshold value $θ$, also refered to as the $bias$.\n",
        "```\n",
        "z1------v1---------\n",
        "                    |\n",
        "                    v\n",
        "z2------v2------> f(net-θ) ------>O\n",
        "                    |\n",
        "                    ^\n",
        "zI------vI---------\n",
        "```"
      ],
      "metadata": {
        "id": "W5c2sdrtJicX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. Calculating the Net Input Signal**\n",
        "\n",
        "- The net input signal to an $AN$ is usually computed as the weighted sum of all input signals, $net = ∑_{i=1}^Iz_iv_i$.\n",
        "\n",
        "- Artificial neurons that compuyr the net input signal as the weighted sum of input signals are refered to as $\\text{ summation units (SU)}$. An alternative to compute the net input signal is to use $\\text{ product units (PU)}$, where $net=∏_{i=1}^Iz_i^{v_i}$,\n",
        "\n"
      ],
      "metadata": {
        "id": "wc_146J7NAo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**III. Activation Functions**\n",
        "- The function $f_{AN}$ receives the net input signal and bias, and determines the output (or firing strength) of the neuron. This function is refered to as the $\\text{activation function }$.\n",
        "\n",
        "1. **Linear Function**:\n",
        "- $f_{AN}(net - θ) = λ(net - θ)$, where $λ$ is the slope of the function. The linear function produces a linearly modulated output, where $λ$ is a constant.\n",
        "\n",
        "2. **Step Function**:\n",
        "- $f_{AN}(net-θ) =\n",
        "\\begin{cases}\n",
        "γ_1 & \\text{if net ≥ θ}\\\\\n",
        "γ_2 & \\text{if net < θ}\\\\\n",
        "\\end{cases}$\n",
        "\n",
        "- The step function produces one of two scalar output values, depending on the value of the threshold $θ$. Usually, a binary output is produced for which $γ_1 = 1$ and $γ_2=0$; a bipolar output is also sometimes used where $γ_1 = 1$ and $y_2 = -1$.\n",
        "\n",
        "3. **Ramp function**:\n",
        "- $f_{AN}(net - θ)=\n",
        "\\begin{cases}\n",
        "γ & \\text{ if net - θ ≥ ϵ}\\\\\n",
        "net - θ & \\text{ if - ϵ < net - θ < ϵ}\\\\\n",
        "-γ  &  \\text{if net - θ ≤ - ϵ}\n",
        "\\end{cases}$\n",
        "\n",
        "- The ramp function is a combination of the linear and step functions.\n",
        "\n",
        "4. **Sigmoid function**:\n",
        "- $f_{AN}(net - θ) = \\frac{1}{1+e^{-λ(net - θ)}}$.\n",
        "- The sigmoid function is a continuous version of the ramp function, with $f_{AN}(net) \\in (0,1)$. The parameter $λ$ controls the steepness of the function. Usually, $λ = 1$.\n"
      ],
      "metadata": {
        "id": "YGvkzaU_QkWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IV. Artificial Neuron Learning**\n",
        "\n",
        "-"
      ],
      "metadata": {
        "id": "La-LE6IWT5kh"
      }
    }
  ]
}